{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a24588c-b6d5-4964-a72c-24a54320edf3",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "# Semi-Supervised Learning with ResNet18 utilizing Pseudolabeling and Entropy-Based Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ccd6c-1549-418b-b627-6b317eb9254a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e79097-f334-4a93-ae26-7d77f2566881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ccc035-bd78-4d0c-bb17-c06569d381a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9431a1-740e-4ef6-a7f1-4dbda6a271b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.1\n",
      "Name of current CUDA device:Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffce5a-6289-4ec0-9adb-ff2b7848330f",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "593b8887-b11f-4850-ac9b-1367dfeb49e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"./files/train_labeled.csv\")\n",
    "categories = pd.read_csv(\"./files/categories.csv\")\n",
    "batch_size = 32\n",
    "seed = torch.manual_seed(40)\n",
    "epochs = 80\n",
    "n_classes = 135\n",
    "lr = 0.01\n",
    "threshold = 0.9\n",
    "e_lambda = 0.6\n",
    "decay_gamma = 0.3\n",
    "pseudo_labmda = 0.5\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.v2.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(45),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "val_loss = []\n",
    "\n",
    "sm = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575113a-12de-44c6-bd3e-9687cac82af9",
   "metadata": {},
   "source": [
    "### Custom Dataloaders for Labeled and Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b929a564-9e73-462f-82a1-a2405dcf4b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, pseudo = \"labeled\", transform = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "        self.pseudo = pseudo\n",
    "    \n",
    "    def get_class_label(self, image_name):\n",
    "        id = (self.labels.loc[self.labels['image'] == image_name])['id'].values[0]\n",
    "        return id\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        x = Image.open(f\"./files/train/{self.pseudo}/{image_path}\")\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        y = self.get_class_label(image_path)\n",
    "        return x, y, image_path\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "        \n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, image_paths, path, transform = None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        x = Image.open(f\"{self.path}{image_path}\")\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, index, image_path\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9b7f4-70ed-4ddc-8d29-52471fa73edf",
   "metadata": {},
   "source": [
    "### Loading Images into Corresponding Datasets and Dataloaders\n",
    "Labeled Dataset Size: 9854\n",
    "<br>\n",
    "Unlabeled Dataset Size: 22995\n",
    "<br>\n",
    "Due to the small labeled datset size to predict 135 classes (15 types of leaves and 120 types of dogs), I utilized semi-supervised learning methods to utilize the unlabeled datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b80fa41-205c-491d-b7a6-38ce1fd8a91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_labeled_dataset = \"./files/train/labeled\"\n",
    "train_unlabeled_dataset = \"./files/train/unlabeled\"\n",
    "test_dataset = \"./files/test\"\n",
    "\n",
    "train_labeled = np.array(os.listdir(train_labeled_dataset))\n",
    "train_unlabeled = np.array(os.listdir(train_unlabeled_dataset))\n",
    "train_unlabeled= train_unlabeled[train_unlabeled!='26804.jpg']\n",
    "test = np.array(os.listdir(test_dataset))\n",
    "test.sort()\n",
    "train_labeled, split_test = train_test_split(train_labeled, test_size = 0.2)\n",
    "train_l = LabeledDataset(train_labeled, labels, \"labeled\", train_transform)\n",
    "train_l_loader = torch.utils.data.DataLoader(train_l, batch_size = batch_size, shuffle = True)\n",
    "split_t = LabeledDataset(split_test, labels, \"labeled\", test_transform)\n",
    "split_t_loader = torch.utils.data.DataLoader(split_t, batch_size = batch_size, shuffle = True)\n",
    "train_ul = UnlabeledDataset(train_unlabeled, \"./files/train/unlabeled/\", test_transform)\n",
    "train_ul_loader = torch.utils.data.DataLoader(train_ul, batch_size = 1, shuffle = True)\n",
    "test_dataset = UnlabeledDataset(test, \"./files/test/\", test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a80885-ee92-453a-9c9a-f294ab6b26f2",
   "metadata": {},
   "source": [
    "### Defining the Classifier (Resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24a969b-c27f-4d39-8d39-4d6553204956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = torchvision.models.resnet18()\n",
    "classifier.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features=135)\n",
    ")\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8bd2fc-3c2a-48ba-997e-42c9bba2522f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name,param in classifier.named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63aae4-a76e-4612-b403-e8589d6d1628",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss, Adam Optimizer with L2 Regularization, and Step Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487627cb-cb83-4612-bc0d-5ac1384f55e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=lr, weight_decay = 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22052d2e-7794-438d-9562-ed6341cb539c",
   "metadata": {},
   "source": [
    "### Training on Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ed090c-50bf-4ed4-8841-73604086359a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labeled_train():\n",
    "    classifier.train()\n",
    "    count = 0\n",
    "    num = 0\n",
    "    den = 0\n",
    "    avg = 0\n",
    "    for index, data in enumerate(train_l_loader):\n",
    "                imgs, tlabels, paths = data\n",
    "                imgs = imgs.to(device)\n",
    "                tlabels = tlabels.to(device)\n",
    "                outputs = classifier(imgs)\n",
    "                loss = criterion(outputs, tlabels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                output_idx = torch.argmax(outputs, dim=1)\n",
    "                num = (output_idx == tlabels).sum()\n",
    "                den = len(output_idx) + den\n",
    "                avg = avg + loss.item()\n",
    "                count = count + 1\n",
    "    train_loss.append(avg/count)\n",
    "    train_acc.append(num/den)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cced17-ce49-4a3b-bf75-5ae644afcd59",
   "metadata": {},
   "source": [
    "### Entropy-Based Regularization\n",
    "<br>\n",
    "<img src=\"entropyreg.gif\">\n",
    "<br>\n",
    "I employed entropy-based regularization, producing this loss function:\n",
    "where N is the total number of unlabeled images, L is the number of classes (135), and C represents my classifier. Lambda is a loss function \"adjuster\" that lets us control how much weight we want this unlabeled entropy-based regularization to have in backpropogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6508b8fd-4590-4bc6-b46b-3d434fcd9674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def entropy_reg():\n",
    "    classifier.train()\n",
    "    count = 0\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    entropy_loss = 0\n",
    "    for index, data in enumerate(train_ul_loader):\n",
    "                img, pathindex, imagepath = data\n",
    "                img = img.to(device)\n",
    "                output = sm(classifier(img))\n",
    "                entropies = ((torch.log(output) * output) * -1 * e_lambda).sum()\n",
    "                entropies.backward()\n",
    "                entropy_loss = entropy_loss + entropies\n",
    "                count = count + 1\n",
    "                if count % 1000 == 0:\n",
    "                    print(count / 1000)\n",
    "                if count / 1000 == 10:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784636f8-a743-4f02-8057-4b65efde3b69",
   "metadata": {},
   "source": [
    "### Validation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dafd438-29b5-4d2a-a013-74cb1de2c9cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation():\n",
    "    num = 0\n",
    "    den = 0\n",
    "    avg = 0\n",
    "    count = 0\n",
    "    t = 0\n",
    "    classifier.eval()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(split_t_loader):\n",
    "                        img, tlabel, path = data\n",
    "                        img = img.to(device)\n",
    "                        tlabel = tlabel.to(device)\n",
    "                        output = classifier(img)\n",
    "                        loss = criterion(output, tlabel)\n",
    "                        output_idx = torch.argmax(output, dim=1)\n",
    "                        num = (output_idx == tlabel).sum()\n",
    "                        den = len(output_idx) + den\n",
    "                        avg = avg + loss.item()\n",
    "                        count = count + 1\n",
    "    val_loss.append(avg/count)\n",
    "    val_acc.append(num/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7a866-aefb-41b1-9568-767b7c6ca1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(num_epochs):\n",
    "        count = 0\n",
    "        torch.cuda.empty_cache()\n",
    "        for ep in range(num_epochs):\n",
    "            labeled_train()\n",
    "            entropy_reg()\n",
    "            validation()\n",
    "            scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae287a-8e45-4ba3-9cb5-20cde080f515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db3069-32c8-4171-8a82-905e6d844698",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2ea74-1158-49ed-901c-8a6b1edbb04a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = [i for i in range(1,75)]\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, train_loss, label=\"Train\")\n",
    "plt.plot(x, val_loss, label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(x, train_acc)\n",
    "plt.plot(x, val_acc)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2070c189-8402-4e3c-9afd-b6da985cbf74",
   "metadata": {},
   "source": [
    "## Results\n",
    "<br>\n",
    "<img src=\"train-results.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8877639-6cca-408e-96e9-f5495668e2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001, weight_decay = 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7f991-bfbf-4fbb-9cde-bb1920b4df21",
   "metadata": {},
   "source": [
    "### Pseudolabeling\n",
    "Pseudolabelling allows us to capitalize further on our unlabelled dataset. By creating hard labels based off of my classifier's predictions, I was able to expand our available labeled dataset domain in order to train the model. \n",
    "<br>\n",
    "    <img src=\"pseudolabel.gif\">\n",
    "<br>\n",
    "To ensure that my model was only creating hard pseudolabels on images with confidence, I established a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd568c7-4b97-421a-a557-a09935aae064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        classifier.eval()\n",
    "        addcount = 0\n",
    "        num = 0\n",
    "        den = 0\n",
    "        appendlist = []\n",
    "        labelappend = []\n",
    "        imagepaths = []\n",
    "        with torch.no_grad():\n",
    "            for index, data in enumerate(train_ul_loader):\n",
    "                        img, pathindex, imagepath = data\n",
    "                        img = img.to(device)\n",
    "                        output = classifier(img)\n",
    "                        output = sm(output)\n",
    "                        output_idx = torch.argmax(output, dim=1)\n",
    "                        if output[0][output_idx[0]] > threshold:\n",
    "                            appendlist.append(img)\n",
    "                            labelappend.append(int(output_idx[0].cpu()))\n",
    "                            imagepaths.append(imagepath[0])\n",
    "                            addcount = addcount + 1\n",
    "        print(f\"Added: {addcount} / {len(train_unlabeled)}\")\n",
    "        psdict = {\"image\":imagepaths, \"id\":labelappend}\n",
    "        pslabels = pd.DataFrame.from_dict(psdict)\n",
    "        train_ps = LabeledDataset(imagepaths, pslabels, \"unlabeled\", train_transform)\n",
    "        train_ps_loader = torch.utils.data.DataLoader(train_ps, batch_size = batch_size, shuffle = True)\n",
    "        classifier.train()\n",
    "        for i, data in enumerate(train_ps_loader):\n",
    "                imgs, tlabels, paths = data\n",
    "                imgs = imgs.to(device)\n",
    "                tlabels = tlabels.to(device)\n",
    "                outputs = classifier(imgs)\n",
    "                output_idx = torch.argmax(outputs, dim=1)\n",
    "                num = (output_idx == tlabels).sum()\n",
    "                den = len(output_idx) + den\n",
    "                loss = criterion(outputs, tlabels) * pseudo_lambda\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429626a-245e-4a07-bf0c-f8a03e5a0bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b681128-9f07-41eb-ba8e-f9da1f3f44d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = [i for i in range(1,11)]\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, train_loss, label=\"Train\")\n",
    "plt.plot(x, val_loss, label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Pseudolabeled Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(x, train_acc)\n",
    "plt.plot(x, val_acc)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Pseudolabeled Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84bcef-2b9a-4b43-87dd-bc9b8b307064",
   "metadata": {},
   "source": [
    "## Results:\n",
    "<br>\n",
    "<img src=\"pseudo-imgs.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c161e-1930-46d8-a6d6-3502d91d7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in classifier.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94daf60-57ed-4caf-abdc-34760b4f71c8",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "Formatted test classifications into a csv file to be submitted to a kaggle competition where the hidden ground truths for these test labels were compared to the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc586ac8-9f21-4a36-98f5-ce0ece956fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "fin_dict = {}\n",
    "for index, data in enumerate(test_loader):\n",
    "    img, pathindex, path = data\n",
    "    img = img.to(device)\n",
    "    outputs = classifier(img)\n",
    "    max_index = torch.argmax(outputs, dim=1)\n",
    "    # print(max_index)\n",
    "    fin_dict[path] = max_index.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25c4b6-b43e-4976-8bf8-4769e634ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "preds = []\n",
    "for key in fin_dict.keys():\n",
    "    print(key[0])\n",
    "    keys.append(key[0])\n",
    "    preds.append(int(fin_dict[key][0]))\n",
    "input_dict = {\"image\": keys, \"id\": preds}\n",
    "df = pd.DataFrame.from_dict(input_dict)\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8b3cf-343a-4ec0-b3f0-f5d2c0f5d870",
   "metadata": {},
   "source": [
    "## Results:\n",
    "<img src=\"submission.png\">"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
